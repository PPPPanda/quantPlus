#!/usr/bin/env python3
"""
è·³ç©ºåˆ†æè„šæœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰- ä¸ä¾èµ– vnpy

åˆ†æç›®æ ‡ï¼š
1. è¯†åˆ«æ‰€æœ‰è·³ç©ºäº‹ä»¶ï¼ˆsession é—´éš”å¯¼è‡´çš„ gapï¼‰
2. åˆ†æè·³ç©ºç‰¹å¾ï¼ˆå¹…åº¦ã€æ—¶é—´ã€æ–¹å‘ï¼‰
3. ä¸ºç­–ç•¥ä¼˜åŒ–æä¾›æ•°æ®æ”¯æŒ
"""

import os
import sys
import json
from datetime import datetime, time, timedelta
from pathlib import Path
from typing import Optional

import pandas as pd
import numpy as np

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent


def detect_gaps(df: pd.DataFrame, atr_mult: float = 3.0) -> pd.DataFrame:
    """
    æ£€æµ‹è·³ç©ºäº‹ä»¶
    
    Args:
        df: 1åˆ†é’ŸKçº¿æ•°æ®ï¼Œéœ€åŒ…å« datetime, open, high, low, close, volume
        atr_mult: æç«¯è·³ç©ºé˜ˆå€¼ï¼ˆÃ—ATRï¼‰
    
    Returns:
        è·³ç©ºäº‹ä»¶ DataFrame
    """
    df = df.copy()
    df['datetime'] = pd.to_datetime(df['datetime'])
    df = df.sort_values('datetime').reset_index(drop=True)
    
    # è®¡ç®— ATRï¼ˆä½¿ç”¨æ»šåŠ¨14*5=70æ ¹1åˆ†é’Ÿbarï¼Œçº¦ç­‰äº14æ ¹5åˆ†é’Ÿbarï¼‰
    df['tr'] = np.maximum(
        df['high'] - df['low'],
        np.maximum(
            abs(df['high'] - df['close'].shift(1)),
            abs(df['low'] - df['close'].shift(1))
        )
    )
    df['atr'] = df['tr'].rolling(window=70, min_periods=14).mean()
    
    # æ£€æµ‹æ—¶é—´é—´éš”
    df['prev_close'] = df['close'].shift(1)
    df['prev_datetime'] = df['datetime'].shift(1)
    df['time_gap'] = (df['datetime'] - df['prev_datetime']).dt.total_seconds() / 60
    
    # è¯†åˆ« session è·³ç©ºï¼ˆæ—¶é—´é—´éš” > 5 åˆ†é’Ÿï¼‰
    session_gap_mask = df['time_gap'] > 5
    
    # è®¡ç®—è·³ç©ºå¹…åº¦
    df['gap'] = df['open'] - df['prev_close']
    df['gap_abs'] = df['gap'].abs()
    df['gap_atr'] = df['gap_abs'] / df['atr'].clip(lower=1)  # é¿å…é™¤é›¶
    
    # ç­›é€‰æœ‰æ„ä¹‰çš„è·³ç©ºï¼ˆsession é—´éš” + gap > 0.3 ATRï¼‰
    gap_events = df[session_gap_mask & (df['gap_atr'] > 0.3)].copy()
    
    # æ ‡è®°è·³ç©ºç±»å‹
    gap_events['gap_type'] = np.where(gap_events['gap'] > 0, 'gap_up', 'gap_down')
    gap_events['is_extreme'] = gap_events['gap_atr'] > atr_mult
    
    # åˆ¤æ–­è·³ç©ºæ—¶é—´ç±»å‹
    def classify_gap_time(row):
        dt = row['datetime']
        prev_dt = row['prev_datetime']
        gap_hours = row['time_gap'] / 60
        
        # éš”å¤œï¼ˆæ”¶ç›˜åˆ°ä¸‹ä¸€äº¤æ˜“æ—¥å¼€ç›˜ï¼‰
        if gap_hours > 10:
            return 'overnight'
        # åˆä¼‘ï¼ˆ11:30-13:30ï¼‰
        elif gap_hours > 1.5 and dt.hour == 13:
            return 'lunch_break'
        # å¤œç›˜åˆ‡æ¢ï¼ˆ15:00-21:00ï¼‰
        elif gap_hours > 5 and dt.hour == 21:
            return 'day_to_night'
        # èŠ‚å‡æ—¥
        elif gap_hours > 24:
            return 'holiday'
        else:
            return 'other'
    
    gap_events['gap_time_type'] = gap_events.apply(classify_gap_time, axis=1)
    
    return gap_events[['datetime', 'prev_datetime', 'prev_close', 'open', 'close', 
                       'gap', 'gap_abs', 'gap_atr', 'atr', 'gap_type', 'is_extreme', 
                       'time_gap', 'gap_time_type']]


def analyze_contract_gaps(data_file: Path, contract: str) -> dict:
    """åˆ†æå•ä¸ªåˆçº¦çš„è·³ç©ºæƒ…å†µ"""
    print(f"\n{'='*60}")
    print(f"Processing: {contract} - {data_file.name}")
    print(f"{'='*60}")
    
    # åŠ è½½æ•°æ®
    df = pd.read_csv(data_file)
    df['datetime'] = pd.to_datetime(df['datetime'])
    
    print(f"  Data range: {df['datetime'].min()} to {df['datetime'].max()}")
    print(f"  Total bars: {len(df)}")
    
    # æ£€æµ‹è·³ç©º
    gap_events = detect_gaps(df)
    
    if gap_events.empty:
        print(f"  No significant gaps detected")
        return {
            'contract': contract,
            'total_bars': len(df),
            'total_gaps': 0,
            'extreme_gaps': 0,
            'gaps': []
        }
    
    # ç»Ÿè®¡
    total_gaps = len(gap_events)
    extreme_gaps = gap_events['is_extreme'].sum()
    avg_gap = gap_events['gap_abs'].mean()
    avg_gap_atr = gap_events['gap_atr'].mean()
    max_gap = gap_events['gap_abs'].max()
    max_gap_atr = gap_events['gap_atr'].max()
    
    # æŒ‰ç±»å‹ç»Ÿè®¡
    by_type = gap_events.groupby('gap_type').agg({
        'gap': ['count', 'mean', 'sum'],
        'gap_atr': 'mean',
        'is_extreme': 'sum'
    }).round(2)
    
    by_time_type = gap_events.groupby('gap_time_type').agg({
        'gap': ['count', 'mean', 'sum'],
        'gap_atr': 'mean',
        'is_extreme': 'sum'
    }).round(2)
    
    print(f"\n  Total gaps: {total_gaps}")
    print(f"  Extreme gaps (>3 ATR): {extreme_gaps}")
    print(f"  Avg gap: {avg_gap:.0f} pts ({avg_gap_atr:.2f} ATR)")
    print(f"  Max gap: {max_gap:.0f} pts ({max_gap_atr:.2f} ATR)")
    
    print(f"\n  By direction:")
    print(f"    Gap up: {(gap_events['gap_type'] == 'gap_up').sum()}")
    print(f"    Gap down: {(gap_events['gap_type'] == 'gap_down').sum()}")
    
    print(f"\n  By time type:")
    for tt in ['overnight', 'lunch_break', 'day_to_night', 'holiday', 'other']:
        count = (gap_events['gap_time_type'] == tt).sum()
        if count > 0:
            subset = gap_events[gap_events['gap_time_type'] == tt]
            print(f"    {tt}: {count} gaps, avg={subset['gap'].mean():.0f} pts")
    
    # è¯¦ç»†æç«¯è·³ç©ºåˆ—è¡¨
    extreme_list = []
    if extreme_gaps > 0:
        print(f"\n  âš ï¸ Extreme gaps (>3 ATR):")
        for _, row in gap_events[gap_events['is_extreme']].iterrows():
            direction = "â†‘" if row['gap'] > 0 else "â†“"
            print(f"    {row['datetime']} {direction} {row['gap']:.0f} pts ({row['gap_atr']:.1f}Ã—ATR) [{row['gap_time_type']}]")
            extreme_list.append({
                'datetime': str(row['datetime']),
                'prev_datetime': str(row['prev_datetime']),
                'gap': float(row['gap']),
                'gap_atr': float(row['gap_atr']),
                'gap_type': row['gap_type'],
                'gap_time_type': row['gap_time_type'],
            })
    
    # è¿”å›ç»“æœ
    gap_list = []
    for _, row in gap_events.iterrows():
        gap_list.append({
            'datetime': str(row['datetime']),
            'prev_datetime': str(row['prev_datetime']),
            'prev_close': float(row['prev_close']),
            'open': float(row['open']),
            'gap': float(row['gap']),
            'gap_atr': float(row['gap_atr']),
            'gap_type': row['gap_type'],
            'is_extreme': bool(row['is_extreme']),
            'gap_time_type': row['gap_time_type'],
        })
    
    return {
        'contract': contract,
        'total_bars': len(df),
        'total_gaps': total_gaps,
        'extreme_gaps': int(extreme_gaps),
        'avg_gap': float(avg_gap),
        'avg_gap_atr': float(avg_gap_atr),
        'max_gap': float(max_gap),
        'max_gap_atr': float(max_gap_atr),
        'gap_up_count': int((gap_events['gap_type'] == 'gap_up').sum()),
        'gap_down_count': int((gap_events['gap_type'] == 'gap_down').sum()),
        'gaps': gap_list,
        'extreme_list': extreme_list,
    }


def main():
    """ä¸»å‡½æ•°"""
    # æ•°æ®è·¯å¾„
    wind_dir = PROJECT_ROOT / "data" / "analyse" / "wind"
    xt_dir = PROJECT_ROOT / "data" / "analyse"
    
    # å…¨é‡ Wind åˆçº¦
    contracts = [
        ("p2201", wind_dir / "p2201_1min_202108-202112.csv"),
        ("p2205", wind_dir / "p2205_1min_202112-202204.csv"),
        ("p2209", wind_dir / "p2209_1min_202204-202208.csv"),
        ("p2301", wind_dir / "p2301_1min_202208-202212.csv"),
        ("p2305", wind_dir / "p2305_1min_202212-202304.csv"),
        ("p2309", wind_dir / "p2309_1min_202304-202308.csv"),
        ("p2401", wind_dir / "p2401_1min_202308-202312.csv"),
        ("p2405", wind_dir / "p2405_1min_202312-202404.csv"),
        ("p2409", wind_dir / "p2409_1min_202401-202408.csv"),
        ("p2501", wind_dir / "p2501_1min_202404-202412.csv"),
        ("p2505", wind_dir / "p2505_1min_202412-202504.csv"),
        ("p2509", wind_dir / "p2509_1min_202504-202508.csv"),
    ]
    
    # p2601 æ¥è‡ª XTï¼ˆé Windï¼‰
    p2601_file = xt_dir / "p2601_1min_202507-202512.csv"
    if p2601_file.exists():
        contracts.append(("p2601", p2601_file))
    
    all_results = []
    all_extreme_gaps = []
    
    for contract, data_file in contracts:
        if not data_file.exists():
            print(f"Skipping {contract}: file not found at {data_file}")
            continue
        
        try:
            result = analyze_contract_gaps(data_file, contract)
            all_results.append(result)
            
            # æ”¶é›†æ‰€æœ‰æç«¯è·³ç©º
            for eg in result.get('extreme_list', []):
                eg['contract'] = contract
                all_extreme_gaps.append(eg)
                
        except Exception as e:
            print(f"Error processing {contract}: {e}")
            import traceback
            traceback.print_exc()
    
    # æ±‡æ€»ç»Ÿè®¡
    print("\n" + "="*80)
    print("SUMMARY: Gap Statistics Across All Contracts")
    print("="*80)
    
    total_gaps = sum(r['total_gaps'] for r in all_results)
    total_extreme = sum(r['extreme_gaps'] for r in all_results)
    
    print(f"\nTotal gaps across all contracts: {total_gaps}")
    print(f"Total extreme gaps (>3 ATR): {total_extreme}")
    
    # æŒ‰åˆçº¦çš„æç«¯è·³ç©ºç»Ÿè®¡
    print("\n" + "-"*60)
    print("Extreme Gaps by Contract:")
    print("-"*60)
    
    for result in all_results:
        if result['extreme_gaps'] > 0:
            print(f"  {result['contract']}: {result['extreme_gaps']} extreme gaps")
    
    # æ‰€æœ‰æç«¯è·³ç©ºè¯¦ç»†åˆ—è¡¨
    print("\n" + "-"*60)
    print("All Extreme Gaps (sorted by ATR magnitude):")
    print("-"*60)
    
    all_extreme_gaps.sort(key=lambda x: abs(x['gap_atr']), reverse=True)
    for eg in all_extreme_gaps[:30]:  # Top 30
        direction = "ğŸ“ˆ" if eg['gap'] > 0 else "ğŸ“‰"
        print(f"  {direction} {eg['contract']} @ {eg['datetime']}: {eg['gap']:.0f} pts ({eg['gap_atr']:.1f}Ã—ATR) [{eg['gap_time_type']}]")
    
    # åˆ†æè·³ç©ºå¯¹ç­–ç•¥çš„æ½œåœ¨å½±å“
    print("\n" + "="*80)
    print("ANALYSIS: Potential Impact on Strategy")
    print("="*80)
    
    # ç»Ÿè®¡è·³ç©ºæ–¹å‘åˆ†å¸ƒ
    total_gap_up = sum(r['gap_up_count'] for r in all_results)
    total_gap_down = sum(r['gap_down_count'] for r in all_results)
    
    print(f"\nGap direction distribution:")
    print(f"  Gap up: {total_gap_up} ({total_gap_up/total_gaps*100:.1f}%)")
    print(f"  Gap down: {total_gap_down} ({total_gap_down/total_gaps*100:.1f}%)")
    
    # åˆ†ææç«¯è·³ç©ºä¸­å¤šå¤´/ç©ºå¤´æ–¹å‘
    extreme_up = sum(1 for eg in all_extreme_gaps if eg['gap'] > 0)
    extreme_down = sum(1 for eg in all_extreme_gaps if eg['gap'] < 0)
    
    print(f"\nExtreme gap direction:")
    print(f"  Extreme gap up: {extreme_up}")
    print(f"  Extreme gap down: {extreme_down}")
    
    # æŒ‰æ—¶é—´ç±»å‹åˆ†ææç«¯è·³ç©º
    print(f"\nExtreme gaps by time type:")
    time_types = {}
    for eg in all_extreme_gaps:
        tt = eg['gap_time_type']
        if tt not in time_types:
            time_types[tt] = {'count': 0, 'total_gap': 0}
        time_types[tt]['count'] += 1
        time_types[tt]['total_gap'] += eg['gap']
    
    for tt, stats in sorted(time_types.items(), key=lambda x: -x[1]['count']):
        avg_gap = stats['total_gap'] / stats['count'] if stats['count'] > 0 else 0
        print(f"  {tt}: {stats['count']} gaps, avg={avg_gap:.0f} pts")
    
    # ç­–ç•¥å½±å“åˆ†æ
    print("\n" + "-"*60)
    print("Strategy Impact Analysis:")
    print("-"*60)
    
    print("""
å¯¹å¤šå¤´æŒä»“çš„å½±å“ï¼š
  - æç«¯å‘ä¸Šè·³ç©ºï¼ˆgap_upï¼‰ï¼šå¯¹å¤šå¤´æŒä»“æœ‰åˆ©ï¼Œæµ®ç›ˆç¬é—´æ‰©å¤§
  - æç«¯å‘ä¸‹è·³ç©ºï¼ˆgap_downï¼‰ï¼šå¯¹å¤šå¤´æŒä»“ä¸åˆ©ï¼Œå¯èƒ½ç›´æ¥å‡»ç©¿æ­¢æŸ

å¯¹ç­–ç•¥ä¿¡å·çš„å½±å“ï¼š
  - è·³ç©ºç ´åç¼ è®ºè¿ç»­æ€§å‡è®¾
  - åˆ†å‹/ç¬”/ä¸­æ¢ç»“æ„å¯èƒ½å¤±çœŸ
  - èƒŒé©°åˆ¤æ–­çš„ MACD é¢ç§¯è®¡ç®—è¢«æ‰­æ›²

S26 ä¿æŠ¤æœºåˆ¶çš„ä½œç”¨ï¼š
  - æç«¯è·³ç©ºåæš‚åœ 3 æ ¹ 5m bar ä¿¡å·
  - ç­‰å¾…ç»“æ„é‡æ–°ç¨³å®šåå†å…¥åœº
  - é¿å…åœ¨æ··ä¹±æœŸç›²ç›®è¿½æ¶¨æ€è·Œ
""")
    
    # ä¿å­˜ç»“æœåˆ° JSON
    output_file = PROJECT_ROOT / "experiments" / "gap_analysis_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'summary': {
                'total_gaps': total_gaps,
                'total_extreme_gaps': total_extreme,
                'gap_up_count': total_gap_up,
                'gap_down_count': total_gap_down,
            },
            'by_contract': all_results,
            'all_extreme_gaps': all_extreme_gaps,
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nResults saved to: {output_file}")
    
    return all_results


if __name__ == "__main__":
    main()
